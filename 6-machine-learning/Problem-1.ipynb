{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Apply your skills to classify protein foldType with Decision Tree Classifier\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmtfPyspark.ml import SparkMultiClassClassifier, datasetBalancer                                 \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import mltoolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .appName(\"datasetClassifierProblemset\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-1: Read in data from parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parquetFile = './input_features/'\n",
    "data = spark.read.parquet(parquetFile).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-2: Select alpha, beta, alpha+beta foldtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data: 14443\n"
     ]
    }
   ],
   "source": [
    "data = data.where((data.foldType == 'alpha') | (data.foldType == 'beta') | (data.foldType == 'alpha+beta'))\n",
    "print(f\"Total number of data: {data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-3: Downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (balanced)  : 3777\n",
      "+----------+-----+\n",
      "|  foldType|count|\n",
      "+----------+-----+\n",
      "|alpha+beta| 1290|\n",
      "|      beta| 1253|\n",
      "|     alpha| 1234|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = 'foldType'\n",
    "\n",
    "data = datasetBalancer.downsample(data, label, 1)\n",
    "print(f\"Dataset size (balanced)  : {data.count()}\")\n",
    "    \n",
    "data.groupby(label).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-4: Decision Tree Classifier with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class\tTrain\tTest\n",
      "alpha+beta\t913\t377\n",
      "beta\t871\t382\n",
      "alpha\t874\t360\n",
      "\n",
      "Sample predictions: DecisionTreeClassifier\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+-----------------+--------------------+----------+--------------+\n",
      "|structureChainId|     alpha|      beta|      coil|  foldType|            features|indexedLabel|    rawPrediction|         probability|prediction|predictedLabel|\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+-----------------+--------------------+----------+--------------+\n",
      "|          1GVE.B|0.48504984|0.15614618|  0.358804|alpha+beta|[-0.0642171993628...|         0.0|[328.0,85.0,69.0]|[0.68049792531120...|       0.0|    alpha+beta|\n",
      "|          1R4X.A|0.17153284|0.43430656| 0.3941606|alpha+beta|[-0.2385288135872...|         0.0|[328.0,85.0,69.0]|[0.68049792531120...|       0.0|    alpha+beta|\n",
      "|          1T82.B|0.34013605| 0.3605442| 0.2993197|alpha+beta|[-0.1013272784789...|         0.0|[100.0,54.0,22.0]|[0.56818181818181...|       0.0|    alpha+beta|\n",
      "|          2HYY.C|0.44656488|0.17557251| 0.3778626|alpha+beta|[-0.1727037972476...|         0.0| [72.0,22.0,44.0]|[0.52173913043478...|       0.0|    alpha+beta|\n",
      "|          2NQT.B|0.31594202| 0.2173913|0.46666667|alpha+beta|[-0.1495864919792...|         0.0|[328.0,85.0,69.0]|[0.68049792531120...|       0.0|    alpha+beta|\n",
      "+----------------+----------+----------+----------+----------+--------------------+------------+-----------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total time taken: 46.394468784332275\n",
      "\n",
      "Method\tDecisionTreeClassifier\n",
      "F\t0.6615263968417703\n",
      "Accuracy\t0.6577301161751564\n",
      "Precision\t0.6747312683434565\n",
      "Recall\t0.6577301161751564\n",
      "False Positive Rate\t0.1708984297058908\n",
      "True Positive Rate\t0.6577301161751564\n",
      "\t\n",
      "Confusion Matrix\n",
      "['alpha+beta', 'beta', 'alpha']\n",
      "DenseMatrix([[252.,  40.,  85.],\n",
      "             [102., 247.,  33.],\n",
      "             [102.,  21., 237.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "mcc = SparkMultiClassClassifier(dtc, label)\n",
    "matrics = mcc.fit(data)\n",
    "for k,v in matrics.items(): print(f\"{k}\\t{v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Decision Tree Classifier with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class\tTrain\tTest\n",
      "\n",
      "alpha+beta\t892\t398\n",
      "\n",
      "beta\t880\t373\n",
      "\n",
      "alpha\t871\t363\n",
      "\n",
      "Total time taken: 0.37964391708374023\n",
      "\n",
      "Methods\tDecisionTreeClassifier\n",
      "F Score\t0.7048688682381032\n",
      "Accuracy\t0.7072310405643739\n",
      "Precision\t0.7052244843588513\n",
      "Recall\t0.7072310405643739\n",
      "False Positive Rate\t0.14684557411058605\n",
      "True Positive Rate\t0.7094922862329233\n",
      "\t\n",
      "Confusion Matrix\n",
      "['alpha+beta' 'beta' 'alpha']\n",
      "[[240  83  75]\n",
      " [ 50 308  15]\n",
      " [ 80  29 254]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = data.toPandas()\n",
    "dtc = DecisionTreeClassifier()\n",
    "mcc = mltoolkit.MultiClassClassifier(dtc, label)\n",
    "matrics = mcc.fit(df)\n",
    "for k,v in matrics.items(): print(f\"{k}\\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
